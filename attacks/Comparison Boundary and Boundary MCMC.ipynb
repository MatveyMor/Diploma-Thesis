{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "torch.cuda.manual_seed(0)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3*3 convolutino\n",
    "def conv3x3(in_channels, out_channels, stride=1):\n",
    "    return torch.nn.Conv2d(in_channels, out_channels, kernel_size=3,\n",
    "                    stride=stride, padding=1, bias=False)\n",
    "\n",
    "\n",
    "# Residual block\n",
    "class ResidualBlock(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(in_channels, out_channels, stride)\n",
    "        self.bn1 = torch.nn.BatchNorm2d(out_channels)\n",
    "        self.relu = torch.nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(out_channels, out_channels)\n",
    "        self.bn2 = torch.nn.BatchNorm2d(out_channels)\n",
    "        self.downsample = downsample\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        if self.downsample:\n",
    "            residual = self.downsample(x)\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "# ResNet\n",
    "class ResNet(torch.nn.Module):\n",
    "    def __init__(self, block, layers, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_channels = 16\n",
    "        self.conv = conv3x3(1, 16)\n",
    "        self.bn = torch.nn.BatchNorm2d(16)\n",
    "        self.relu = torch.nn.ReLU(inplace=True)\n",
    "        self.layer1 = self.make_layer(block, 16, layers[0])\n",
    "        self.layer2 = self.make_layer(block, 32, layers[0], 1)\n",
    "        self.layer3 = self.make_layer(block, 64, layers[1], 2)\n",
    "        self.layer4 = self.make_layer(block, 128, layers[1], 1)\n",
    "        self.max_pool = torch.nn.MaxPool2d(8)\n",
    "        self.fc = torch.nn.Linear(128, num_classes)\n",
    "\n",
    "    def make_layer(self, block, out_channels, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if (stride != 1) or (self.in_channels != out_channels):\n",
    "            downsample = torch.nn.Sequential(\n",
    "                conv3x3(self.in_channels, out_channels, stride=stride),\n",
    "                torch.nn.BatchNorm2d(out_channels))\n",
    "        layers = []\n",
    "        layers.append(block(self.in_channels, out_channels, stride, downsample))\n",
    "        self.in_channels = out_channels\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(out_channels, out_channels))\n",
    "        return torch.nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv(x)\n",
    "        out = self.bn(out)\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = self.max_pool(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (layer1): Sequential(\n",
       "    (0): ResidualBlock(\n",
       "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): ResidualBlock(\n",
       "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): ResidualBlock(\n",
       "      (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): ResidualBlock(\n",
       "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): ResidualBlock(\n",
       "      (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): ResidualBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): ResidualBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): ResidualBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (max_pool): MaxPool2d(kernel_size=8, stride=8, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc): Linear(in_features=128, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = torch.load('/home/matvey/Morozov/Научрук/Диплом/Diploma-Thesis/Модель/Models/FashionMNIST_ResNet.pth', map_location=torch.device('cpu'))\n",
    "net = net.to('cpu')\n",
    "net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tf = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "test = torchvision.datasets.FashionMNIST('/home/matvey/Morozov/Научрук/Диплом/Diploma-Thesis/Модель/Datasets', download=False, train=False, transform=test_tf)\n",
    "testloader = torch.utils.data.DataLoader(dataset=test, batch_size=256, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = {\n",
    "0 : 'T-shirt/top',\n",
    "1 : 'Trouser',\n",
    "2 : 'Pullover',\n",
    "3 : 'Dress',\n",
    "4 : 'Coat',\n",
    "5 : 'Sandal',\n",
    "6 : 'Shirt',\n",
    "7 : 'Sneaker',\n",
    "8 : 'Bag',\n",
    "9 : 'Ankle boot'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.linalg import norm\n",
    "from scipy.special import softmax\n",
    "\n",
    "examples = enumerate(testloader)\n",
    "batch_idx, (example_data, example_targets) = next(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = torchvision.datasets.FashionMNIST('/home/matvey/Morozov/Научрук/Диплом/Diploma-Thesis/Модель/Datasets', download=False, train=True, transform=test_tf)\n",
    "trainloader = torch.utils.data.DataLoader(dataset=test, batch_size=10000, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_examples = enumerate(trainloader)\n",
    "batch_idx, (train_data, train_targets) = next(train_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from boundary_MCMC import boundary_attack_MCMC\n",
    "from boundary import boundary_attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nearest_image(image, label, train_data, train_targets):\n",
    "    image = image.data.cpu().numpy()[0]\n",
    "    all_norm = []\n",
    "    for i, train_image in enumerate(train_data):\n",
    "        if train_targets[i].data.cpu().numpy() != label:\n",
    "            train_image = train_image.data.cpu().numpy()\n",
    "            diff = train_image - image\n",
    "            norm_diff = norm(diff)\n",
    "            all_norm.append(norm_diff)\n",
    "        else:\n",
    "            all_norm.append(1e20)            \n",
    "\n",
    "    index = np.argmin(all_norm)\n",
    "    return index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Boundary attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start boundary attack\n",
      "distance: 0.0683, itetarion: 5001\n",
      "Start boundary attack\n",
      "distance: 0.0554, itetarion: 5001\n",
      "Start boundary attack\n",
      "distance: 0.1476, itetarion: 5001\n",
      "Start boundary attack\n",
      "distance: 0.1527, itetarion: 5001\n",
      "Start boundary attack\n",
      "distance: 0.1261, itetarion: 5001\n",
      "Start boundary attack\n",
      "distance: 0.1407, itetarion: 5001\n",
      "Start boundary attack\n",
      "distance: 0.1987, itetarion: 5001\n",
      "Start boundary attack\n",
      "distance: 0.3073, itetarion: 5001\n",
      "Start boundary attack\n",
      "distance: 0.0816, itetarion: 5001\n",
      "Start boundary attack\n",
      "distance: 0.0834, itetarion: 5001\n",
      "Start boundary attack\n",
      "distance: 0.1953, itetarion: 5001\n",
      "Start boundary attack\n",
      "distance: 0.1022, itetarion: 5001\n",
      "Start boundary attack\n",
      "distance: 0.1263, itetarion: 5001\n",
      "Start boundary attack\n",
      "distance: 0.0000, itetarion: 5001\n",
      "Start boundary attack\n",
      "distance: 0.0000, itetarion: 5001\n",
      "Start boundary attack\n",
      "distance: 0.1252, itetarion: 5001\n",
      "Start boundary attack\n",
      "distance: 0.1493, itetarion: 5001\n",
      "Start boundary attack\n",
      "distance: 0.0000, itetarion: 5001\n",
      "Start boundary attack\n",
      "distance: 0.0753, itetarion: 5001\n",
      "Start boundary attack\n",
      "distance: 0.0000, itetarion: 5001\n",
      "Start boundary attack\n",
      "distance: 0.0898, itetarion: 5001\n",
      "Start boundary attack\n",
      "distance: 0.0979, itetarion: 5001\n",
      "Start boundary attack\n",
      "distance: 0.0000, itetarion: 5001\n",
      "Start boundary attack\n",
      "distance: 0.0486, itetarion: 5001\n",
      "Start boundary attack\n",
      "distance: 0.3822, itetarion: 5001\n",
      "Start boundary attack\n",
      "distance: 0.0165, itetarion: 5001\n",
      "Start boundary attack\n",
      "distance: 0.0605, itetarion: 5001\n",
      "Start boundary attack\n",
      "distance: 0.0000, itetarion: 5001\n",
      "Start boundary attack\n",
      "distance: 0.0707, itetarion: 5001\n",
      "Start boundary attack\n",
      "distance: 0.0793, itetarion: 5001\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "\n",
    "l1_norm = []\n",
    "l2_norm = []\n",
    "probs_init = []\n",
    "probs_adv = []\n",
    "\n",
    "while True:\n",
    "    class_label = example_targets[i].data.numpy()\n",
    "    image = example_data[i]\n",
    "    label = example_targets[i].data.numpy()\n",
    "\n",
    "    prediction = net(torch.tensor(image.reshape(1, 1, 28, 28))).data.numpy()\n",
    "    prob_init = np.max(softmax(prediction))\n",
    "\n",
    "    index = nearest_image(image, label, train_data, train_targets)\n",
    "    x_init = train_data[index].data.numpy().reshape(28,28)\n",
    "    x_target = example_data[i].data.numpy().reshape(28,28)\n",
    "\n",
    "    adv_example, proba = boundary_attack(net, x_init, x_target, threshold=None, verbose=1, max_iter=5e3)\n",
    "\n",
    "    l1 = np.linalg.norm(adv_example - x_target, ord=1)\n",
    "    l2 = np.linalg.norm(adv_example - x_target, ord=2)\n",
    "    probs_init.append(prob_init)\n",
    "    probs_adv.append(proba)\n",
    "    l1_norm.append(l1)\n",
    "    l2_norm.append(l2)\n",
    "    \n",
    "    i += 1\n",
    "    \n",
    "    if i >= 30:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.24114148082180678, 0.18043313546536685, 0.4847651059800589, 0.5388055075428733, 0.458960110817897, 0.5069033549659488, 0.6044546054488082, 1.014176389330994, 0.2636660183904034, 0.2876706967769222, 0.701438256866413, 0.37064203240221216, 0.40868881618738767, 6.442700650182438e-25, 3.3324097443911234e-24, 0.4388125680948526, 0.5170826108336536, 1.079290929264249e-25, 0.27442586926329154, 6.791056577355476e-24, 0.3292480368088997, 0.3416398265998047, 1.2434919860522619e-25, 0.1856378544511018, 1.417215223733199, 0.05524213949897118, 0.20739116987885522, 9.629471883406152e-25, 0.23476290719031864, 0.25835870489094187]\n",
      "[0.06825219647428395, 0.05538283177503224, 0.1475644622996372, 0.15269663976117007, 0.12612338920721122, 0.14071479507772974, 0.19867633312157368, 0.3073042718211766, 0.08158041675877216, 0.08338847474412843, 0.195318298141276, 0.10219454585041834, 0.1262900451987517, 3.401732806986504e-25, 3.291352290143727e-24, 0.125190060513033, 0.149322415181229, 1.0315600021906346e-25, 0.0752804534888915, 6.523696138863998e-24, 0.08982714834961532, 0.09785064489747627, 1.0313121822798531e-25, 0.048605463391295095, 0.38222055968331825, 0.0164980674009107, 0.06051676430550657, 5.149119987256844e-25, 0.07070004811137018, 0.07927186008759655]\n",
      "[1.0, 0.9999771, 1.0, 1.0, 0.9584389, 1.0, 0.99997234, 0.99999905, 0.99999905, 1.0, 0.99999714, 1.0, 0.99997807, 0.99999714, 0.9958601, 1.0, 0.99999905, 0.5717331, 1.0, 0.99999523, 0.9691764, 0.9999008, 1.0, 0.9899571, 1.0, 0.6615327, 0.99999046, 0.99878, 0.9993736, 0.99975115]\n",
      "[0.50310946, 0.49438918, 0.4679213, 0.5055726, 0.3432543, 0.50068355, 0.5639391, 0.50116247, 0.50470394, 0.49986234, 0.5095306, 0.43628114, 0.55677736, 0.99999714, 0.9958601, 0.4772006, 0.51309586, 0.5717331, 0.47001818, 0.99999523, 0.35330808, 0.5255212, 1.0, 0.510397, 0.20058194, 0.40285882, 0.5107493, 0.99878, 0.5029154, 0.5637357]\n"
     ]
    }
   ],
   "source": [
    "print(l1_norm)\n",
    "print(l2_norm)\n",
    "print(probs_init)\n",
    "print(probs_adv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boundary MCMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start boundary attack\n",
      "distance: 0.0786, itetarion: 20001, alpha: 0.902, probability: 0.499\n",
      "Start boundary attack\n",
      "distance: 0.0553, itetarion: 2917, alpha: 0.975, probability: 0.492\n",
      "Start boundary attack\n",
      "distance: 0.1478, itetarion: 17887, alpha: 0.636, probability: 0.494\n",
      "Start boundary attack\n",
      "distance: 0.1527, itetarion: 3874, alpha: 0.632, probability: 0.506\n",
      "Start boundary attack\n",
      "distance: 0.1259, itetarion: 1842, alpha: 0.741, probability: 0.334\n",
      "Start boundary attack\n",
      "distance: 0.1408, itetarion: 5130, alpha: 0.612, probability: 0.515\n",
      "Start boundary attack\n",
      "distance: 0.2463, itetarion: 20001, alpha: 1.522, probability: 0.527\n",
      "Start boundary attack\n",
      "distance: 0.3067, itetarion: 3663, alpha: 0.944, probability: 0.519\n",
      "Start boundary attack\n",
      "distance: 0.0901, itetarion: 20001, alpha: 0.554, probability: 0.509\n",
      "Start boundary attack\n",
      "distance: 0.0830, itetarion: 6984, alpha: 0.860, probability: 0.501\n",
      "Start boundary attack\n",
      "distance: 0.3232, itetarion: 2116, alpha: 0.607, probability: 0.422"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "\n",
    "l1_norm_MCMC = []\n",
    "l2_norm_MCMC = []\n",
    "probs_init_MCMC = []\n",
    "probs_adv_MCMC = []\n",
    "\n",
    "while True:\n",
    "    class_label = example_targets[i].data.numpy()\n",
    "    image = example_data[i]\n",
    "    label = example_targets[i].data.numpy()\n",
    "    \n",
    "    prediction = net(torch.tensor(image.reshape(1, 1, 28, 28))).data.numpy()\n",
    "    prob_init = np.max(softmax(prediction))\n",
    "    \n",
    "    index = nearest_image(image, label, train_data, train_targets)\n",
    "    x_init = train_data[index].data.numpy().reshape(28,28)\n",
    "    x_target = example_data[i].data.numpy().reshape(28,28)\n",
    "    \n",
    "    adv_example, proba = boundary_attack_MCMC(net, x_init, x_target, threshold=l2_norm[i], max_iter=2e4, verbose=1)\n",
    "    \n",
    "    l1 = np.linalg.norm(adv_example - x_target, ord=1)\n",
    "    l2 = np.linalg.norm(adv_example - x_target, ord=2)\n",
    "    probs_init_MCMC.append(prob_init)\n",
    "    probs_adv_MCMC.append(proba)\n",
    "    l1_norm_MCMC.append(l1)\n",
    "    l2_norm_MCMC.append(l2)\n",
    "    \n",
    "    i += 1\n",
    "    \n",
    "    if i >= 30:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(probs_adv_MCMC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(probs_adv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
